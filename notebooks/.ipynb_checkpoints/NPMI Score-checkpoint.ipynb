{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tf_idf_repr(topics, cw_words, tf_idf_t):\n",
    "    cw_frequency = {}\n",
    "    cw_docs = {}\n",
    "    for iter_topic in topics:\n",
    "        for word in iter_topic:\n",
    "            word_index = np.where(cw_words == word)[0]\n",
    "            cw_frequency[word] = float(tf_idf_t[word_index].getnnz(1))\n",
    "            cw_docs[word] = set(tf_idf_t[word_index].nonzero()[1])\n",
    "\n",
    "    n_docs = 0\n",
    "    for _cw in range(tf_idf_t.shape[0]):\n",
    "        n_docs += float(tf_idf_t[_cw].getnnz(1))\n",
    "\n",
    "    return cw_frequency, cw_docs, n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(topics, word_frequency, term_docs, n_docs, n_top_words):\n",
    "    pmi = []\n",
    "    npmi = []\n",
    "\n",
    "    n_top_words = float(n_top_words)\n",
    "\n",
    "    for t in range(len(topics)):\n",
    "        top_w = topics[t]\n",
    "        # top_w = topico.split(' ')\n",
    "\n",
    "        pmi_t = 0.0\n",
    "        npmi_t = 0.0\n",
    "\n",
    "        for j in range(1, len(top_w)):\n",
    "            for i in range(0, j):\n",
    "                ti = top_w[i]\n",
    "                tj = top_w[j]\n",
    "\n",
    "                c_i = word_frequency[ti]\n",
    "                c_j = word_frequency[tj]\n",
    "                c_i_and_j = len(term_docs[ti].intersection(term_docs[tj]))\n",
    "\n",
    "                pmi_t += np.log(((c_i_and_j + 1.0) / float(n_docs)) /\n",
    "                                ((c_i * c_j) / float(n_docs) ** 2))\n",
    "\n",
    "                npmi_t += -1.0 * np.log((c_i_and_j + 0.01) / float(n_docs))\n",
    "\n",
    "        peso = 1.0 / (n_top_words * (n_top_words - 1.0))\n",
    "\n",
    "        pmi.append(peso * pmi_t)\n",
    "        npmi.append(pmi_t / npmi_t)\n",
    "\n",
    "    return pmi, npmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"uber\"\n",
    "source = \"../fasttext_wiki_bert_max\"\n",
    "top_words = 20\n",
    "hierarchical_file = f\"{source}/results/{dataset}/hierarchical_struture.txt\"\n",
    "npz_input_file = f\"{source}/results/{dataset}/cluwords_representation_{dataset}.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [], 2: []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = {\n",
    "    0: list(),\n",
    "    1: list(),\n",
    "    2: list()\n",
    "}\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hierarchical_file) as hierachical_input:\n",
    "    for topic in hierachical_input:\n",
    "        if topic.startswith(\"\\t\\t\"):\n",
    "            topics[2].append(topic.replace(\"\\t\\t\", \"\").strip().split(\" \"))\n",
    "        elif topic.startswith(\"\\t\"):\n",
    "            topics[1].append(topic.replace(\"\\t\", \"\").strip().split(\" \"))\n",
    "        else:\n",
    "            topics[0].append(topic.strip().split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded  = np.load(npz_input_file)\n",
    "cluwords_repr = loaded['tfidf']\n",
    "cluwords_vocab = loaded['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluwords_freq, cluwords_docs, n_docs = count_tf_idf_repr(topics[0],\n",
    "                                                         cluwords_vocab,\n",
    "                                                         csr_matrix(cluwords_repr).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_0, npmi_0 = pmi(topics=topics[0],\n",
    "                word_frequency=cluwords_freq,\n",
    "                term_docs=cluwords_docs,\n",
    "                n_docs=n_docs,\n",
    "                n_top_words=top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluwords_freq, cluwords_docs, n_docs = count_tf_idf_repr(topics[1],\n",
    "                                                         cluwords_vocab,\n",
    "                                                         csr_matrix(cluwords_repr).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_1, npmi_1 = pmi(topics=topics[1],\n",
    "                word_frequency=cluwords_freq,\n",
    "                term_docs=cluwords_docs,\n",
    "                n_docs=n_docs,\n",
    "                n_top_words=top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluwords_freq, cluwords_docs, n_docs = count_tf_idf_repr(topics[2],\n",
    "                                                         cluwords_vocab,\n",
    "                                                         csr_matrix(cluwords_repr).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_2, npmi_2 = pmi(topics=topics[2],\n",
    "                word_frequency=cluwords_freq,\n",
    "                term_docs=cluwords_docs,\n",
    "                n_docs=n_docs,\n",
    "                n_top_words=top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth_0 0.9596271989177383 0.023698397054884413\n",
      "Depth_1 0.9397599022420315 0.034727460690898666\n",
      "Depth_2 0.9022070756863788 0.04083932554365045\n",
      "Overall 0.9069380827160495 0.042099472650988255\n"
     ]
    }
   ],
   "source": [
    "print(f\"Depth_0 {np.mean(npmi_0)} {np.std(npmi_0, ddof=1)}\")\n",
    "print(f\"Depth_1 {np.mean(npmi_1)} {np.std(npmi_1, ddof=1)}\")\n",
    "print(f\"Depth_2 {np.mean(npmi_2)} {np.std(npmi_2, ddof=1)}\")\n",
    "print(f\"Overall {np.mean(npmi_0 + npmi_1 + npmi_2)} {np.std(npmi_0 + npmi_1 + npmi_2, ddof=1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
